{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44635f8e-c1b6-44bb-86df-67006ec8c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from torchvision.io.image import decode_image\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "def batched(array, size):\n",
    "    array_iter = iter(array) \n",
    "    while True: \n",
    "        b = []\n",
    "        try: [b.append(next(array_iter)) for _ in range(size)]\n",
    "        except: StopIteration\n",
    "        if b: yield b \n",
    "        else: break\n",
    "\n",
    "def annotate_and_save(img, prediction, save_file, categories):\n",
    "    labels = [categories[i] for i in prediction[\"labels\"]]\n",
    "    box = draw_bounding_boxes(\n",
    "        image=img, \n",
    "        boxes=prediction['boxes'], \n",
    "        labels=labels, \n",
    "        colors=\"red\", \n",
    "        width=4, \n",
    "        font=\"Helvetica.ttf\" if os.path.exists(\"Helvetica.ttf\") else None, \n",
    "        font_size=30\n",
    "    )\n",
    "    im = to_pil_image(box.detach())\n",
    "    im.save(save_file)\n",
    "\n",
    "def detect_annotate_save(images, save_files, preprocess, model, categories): \n",
    "    processed_images = [preprocess(image) for image in images]\n",
    "    predictions = model(processed_images) \n",
    "    for image, prediction, fname in zip(images, predictions, save_files): \n",
    "        annotate_and_save(image, prediction, fname, categories)\n",
    "\n",
    "def detection2D(files, output_dir='output', batch_size=5, ):\n",
    "    logger = logging.getLogger(\"detection2D\")\n",
    "    if not os.path.isdir(output_dir): \n",
    "        logger.warning(f\"Output directory '{output_dir}' was not found. Creating directory '{output_dir}'\")\n",
    "        os.mkdir(output_dir)\n",
    "    fnames = [os.path.basename(f) for f in files]\n",
    "    save_files = [os.path.join(output_dir, p) for p in fnames]\n",
    "    imgs = [(decode_image(f), sf) for f, sf in zip(files, save_files)]\n",
    "    batches = batched(imgs, batch_size) \n",
    "    batches = (tuple(zip(*b)) for b in batches)\n",
    "    logger.info(\"Loading model\")\n",
    "    weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.9)\n",
    "    model.eval()\n",
    "    preprocess = weights.transforms()\n",
    "    logger.info(\"Starting detection\")\n",
    "    for batch in tqdm(batches, total=math.ceil(len(imgs)/batch_size)):\n",
    "        images, save_names = batch\n",
    "        detect_annotate_save(images, save_names, preprocess, model, weights.meta[\"categories\"])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33eed22e-03d5-4815-b587-eaa6a852f4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:detection2D:Output directory 'output2' was not found. Creating directory 'output2'\n",
      "INFO:detection2D:Loading model\n",
      "INFO:detection2D:Starting detection\n",
      "  0%|                                                                                                                                      | 0/24 [00:00<?, ?it/s]/home/raka/Projects/InferenceOptimization/.env/lib/python3.10/site-packages/torchvision/utils.py:211: UserWarning: boxes doesn't contain any box. No box was drawn\n",
      "  warnings.warn(\"boxes doesn't contain any box. No box was drawn\")\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [04:10<00:00, 10.45s/it]\n"
     ]
    }
   ],
   "source": [
    "files = [os.path.join(\"pics\", f) for f in os.listdir(\"pics\")] \n",
    "logging.basicConfig(level=logging.INFO)\n",
    "detection2D(files,output_dir=\"output2\",batch_size=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ca194-c2cd-47fc-8f33-f6f137157bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
